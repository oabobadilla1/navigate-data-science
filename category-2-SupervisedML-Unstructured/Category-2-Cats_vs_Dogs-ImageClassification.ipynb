{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category-2-Supervised Machine Learning on Unstructured (Images) data\n",
    "> Dataset consists of images of cats & dogs taken from Kaggle (https://www.kaggle.com/c/dogs-vs-cats/). The training dataset is labeled and thus this is a Supervised Image Classification problem.\n",
    "> Given below is a simple CNN architecture that helps with image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Part 1 - Initializing the CNN **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialising the CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 1 - Convolution\n",
    "# Convolution operator for filtering windows of two-dimensional inputs.\n",
    "# For the first layer in the model,use argument, input_shape=(64, 64, 3)`for 64x64 RGB pictures with Tensorflow backend\n",
    "# 32,3,3 means - Apply a 3x3 convolution with 32 output filters\n",
    "\n",
    "classifier.add(Convolution2D(32, 3, 3, input_shape = (64, 64, 3), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 2 - Pooling\n",
    "# Max pooling operation to capture spatial features\n",
    "# pool_size is the stride window size\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding a second convolutional layer\n",
    "# Input dim is not required for Convolution2D as this is not the first layer\n",
    "classifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier.add(Dense(output_dim = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compiling the CNN\n",
    "# Binary cross entropy is used as there are only 2 classes - cats & dogs\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Part 2 - Fitting the CNN to the images **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ImageDataGenerator in Keras is used for Image Augmentation\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Flow from Directory expects the data to be organized in a certain way: Root folder having subfolders for each class\n",
    "training_set = train_datagen.flow_from_directory('0.datasets/catsdogs/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('0.datasets/catsdogs/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "8000/8000 [==============================] - 684s - loss: 0.6847 - acc: 0.5457 - val_loss: 0.6841 - val_acc: 0.5165\n",
      "Epoch 2/3\n",
      "8000/8000 [==============================] - 151s - loss: 0.6492 - acc: 0.6169 - val_loss: 0.6206 - val_acc: 0.6785\n",
      "Epoch 3/3\n",
      "8000/8000 [==============================] - 528s - loss: 0.5904 - acc: 0.6746 - val_loss: 0.5567 - val_acc: 0.7135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x203dfbbc9e8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set,\n",
    "                         samples_per_epoch = 8000,\n",
    "                         nb_epoch = 3,  # No.of rounds. Higher number = Higher Accuracy but more time to train\n",
    "                         validation_data = test_set,\n",
    "                         nb_val_samples = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Part 3 - Making predictions for new images **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_predict = pd.DataFrame()\n",
    "to_predict['Images'] = ''\n",
    "to_predict['Prediction'] = ''\n",
    "predictions=[]\n",
    "#print(training_set.class_indices)\n",
    "\n",
    "to_predict_image_path = '0.datasets/catsdogs/to_predict_set/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):  # 10 images are present in the to-predict folder\n",
    "    x = str(i+1)\n",
    "    img_name = 'Img' + x + '.jpg'\n",
    "    to_predict_image_string = to_predict_image_path + img_name \n",
    "    temp_image = image.load_img(to_predict_image_string,target_size = (64, 64))\n",
    "    temp_image = image.img_to_array(temp_image)\n",
    "    temp_image = np.expand_dims(temp_image,axis = 0)\n",
    "    result = classifier.predict_classes(temp_image)\n",
    "    if result[0][0] == 1:\n",
    "        prediction = 'dog'\n",
    "    else:\n",
    "        prediction = 'cat'\n",
    "    \n",
    "    to_predict.at[i, 'Images'] = img_name\n",
    "    to_predict.at[i, 'Prediction'] = prediction\n",
    "    predictions.append(prediction)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Images Prediction\n",
      "0   Img1.jpg        dog\n",
      "1   Img2.jpg        dog\n",
      "2   Img3.jpg        dog\n",
      "3   Img4.jpg        cat\n",
      "4   Img5.jpg        dog\n",
      "5   Img6.jpg        cat\n",
      "6   Img7.jpg        cat\n",
      "7   Img8.jpg        dog\n",
      "8   Img9.jpg        cat\n",
      "9  Img10.jpg        dog\n"
     ]
    }
   ],
   "source": [
    "# Final prediction\n",
    "print(to_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
